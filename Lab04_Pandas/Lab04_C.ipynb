{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRr1mwRkju23"
   },
   "source": [
    "#C. Data Analysis and Visualization for Climate Change (60 points)\n",
    "In this part, you will work with a dataset GlobalLandTemperaturesByState.csv containing historical climate data for states across the world from the year 1744 to 2013. The dataset includes average temperature for various states and their respective date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7ZIjRTNju24"
   },
   "source": [
    "### **Question 1: Data Import (6 points)**\n",
    "Use Pandas to import the climate change dataset into a DataFrame called `df_state`. Then find out all the country names from the 'Country' column and print them out. (there are a total of seven unique country names.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlmrJ2L4ju25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-VfKc0Oju25",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the climate change dataset GlobalLandTemperaturesByState.csv into a DataFrame called df_state.\n",
    "\n",
    "# TODO_1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiPlXVuCju25"
   },
   "outputs": [],
   "source": [
    "# Using Pandas to find out all the country names from the 'Country' column and print them out.\n",
    "# Your output should print seven unique country names.\n",
    "\n",
    "# TODO_1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svxqObatju25"
   },
   "source": [
    "### **Question 2: Data Cleaning (12 points, 12 points)**\n",
    "The first step in examining any dataset involves the preparation and refinement of the data. Various forms of irregularities can occur during the data collection or curation process, and it is essential to rectify these issues before conducting any analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0O6LUAFju26"
   },
   "source": [
    "\n",
    "\n",
    "**i.** Implement the function ***cleanse_country_data*** that does the followings:\n",
    "- Some country names include additional abbreviation, such as \"United States (US)\". Create the function to simplify these names, we should discard any additional abbreviation. In a broader sense, any country name in the format \"name1 (name2)\" should be replaced with just \"name1\".\n",
    "- The list `countries_to_remove` is provided because the data for these countries is inaccurate or incomplete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVt0_qsZju26",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries_to_remove = ['Brazil', 'Russia']\n",
    "def cleanse_country_data(df):\n",
    "    \"\"\"\n",
    "    Remove countries in the countries_to_remove list from the dataframe df_state\n",
    "    and simplify the country names that include additional abbreviation.\n",
    "\n",
    "    kwargs:\n",
    "        country_data (pd.DataFrame) : the input dataframe to preprocess\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame : the preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO_2.1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_preprocess_countries():\n",
    "    df_country_cleaned = cleanse_country_data(df_state.copy())\n",
    "    assert df_country_cleaned.columns.equals(df_state.columns)\n",
    "    assert df_country_cleaned.dtypes.equals(df_state.dtypes)\n",
    "    assert len(df_country_cleaned) == 29699\n",
    "    \n",
    "    unique_countries = df_country_cleaned[\"Country\"].unique()\n",
    "    assert len(unique_countries) == 5\n",
    "    assert 'United States' in unique_countries\n",
    "    assert 'Brazil' not in unique_countries\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_preprocess_countries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLtXGt0iju26"
   },
   "source": [
    "**ii.** Missing data can cause issues when we're analyzing the data, and the easiest way to deal with this is to delete rows that have any missing values. Create the function ***drop_missing_values*** to eliminate rows in our datasets that have missing values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pEecMaZju26",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_missing_values(df):\n",
    "    \"\"\"\n",
    "    Drop rows with at least one missing value from an input dataframe.\n",
    "\n",
    "    args:\n",
    "        df (pd.DataFrame) : an input dataframe\n",
    "\n",
    "    returns:\n",
    "        pd.DataFrame : a subset of df where rows with missing values in any column are removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO_2.2\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "df_country_filtered = drop_missing_values(df_state.copy())\n",
    "assert df_country_filtered.columns.equals(df_state.columns)\n",
    "assert df_country_filtered.dtypes.equals(df_state.dtypes)\n",
    "assert len(df_country_filtered) == 51831\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RIH7ZhTju26"
   },
   "source": [
    "### **Question 3: Data Analysis (12 points)**\n",
    "\n",
    "We can get an overview of our dataset by examining summary statistics. To do this, we will use\n",
    "Pandas to load DataFrame and then display key statistics such as\n",
    "the minimum value, maximum value, average (mean), and standard deviation of the\n",
    " \"AverageTemperature\" column in `df_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObET1Lu4ju26"
   },
   "outputs": [],
   "source": [
    "# Show the key statistics such as the minimum value, maximum value, average (mean),\n",
    "# and standard deviation of the \"AverageTemperature\" column in df_state.\n",
    "\n",
    "# TODO_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH-IRhetju26"
   },
   "source": [
    "### **Question 4: Outlier Detection (12 points, 6 points)**\n",
    "\n",
    "We can identify outliers using the Interquartile Range (IQR) rule: a data point is considered outlier if it is at least 1.5 interquartile ranges below the first quartile (Q1), or at least 1.5 interquartile ranges above the third quartile (Q3), i.e.,\n",
    "\n",
    "### $$\\text{outlier} \\le Q1 - 1.5 \\times IQR \\text{  OR  } \\text{outlier} \\ge Q3 + 1.5 \\times IQR.$$\n",
    "\n",
    " Introduction of IQR: https://en.wikipedia.org/wiki/Interquartile_range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1pG-359ju26"
   },
   "source": [
    "Create a function named ***remove_outliers***. This function will be responsible for removing rows from a DataFrame where the values in a specified column are identified as outliers based on the IQR rule.\n",
    "\n",
    "After creating the function, apply it to the \"AverageTemperature\" column in our DataFrame `df_state` store the result in a new DataFrame called `df_removed`. Next, compare the minimum value, maximum value, average (mean), and standard deviation of `df_removed` to those of `df_state` where the ***remove_outliers*** function was not used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn0MlLerju26"
   },
   "outputs": [],
   "source": [
    "def remove_outliers(df, col):\n",
    "    \"\"\"\n",
    "    Remove any row whose data at a given column is considered outlier according to the IQR rule.\n",
    "\n",
    "        args:\n",
    "        df (pd.DataFrame) : an input dataframe where outlier rows should be removed\n",
    "        col (str) : the column name to check for outlier\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame : a subset of the input dataframe after outlier rows are removed\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO_4\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_remove_outliers():\n",
    "    df_country_new = remove_outliers(df_state.copy(), \"AverageTemperature\")\n",
    "    assert df_state.columns.equals(df_state.columns)\n",
    "    assert df_state.dtypes.equals(df_state.dtypes)\n",
    "    assert len(df_country_new) == 53786\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].min() + 42.97) < 0.01\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].max() - 32.21) < 0.01\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].mean() + 3.36) < 0.01\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_remove_outliers()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
